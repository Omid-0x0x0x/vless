#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Simple Config Processor - Ø¯Ø§Ù†Ù„ÙˆØ¯ØŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ Split Ø¨Ø¯ÙˆÙ† Ù¾ÛŒÙ†Ú¯
"""

import urllib.request
import base64
import re
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Set
from collections import defaultdict

class SimpleProcessor:
    def __init__(self, split_size: int = 300):
        self.split_size = split_size
        self.configs: Set[str] = set()  # Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒ
        
    def is_base64(self, text: str) -> bool:
        """Ú†Ú© Ú©Ø±Ø¯Ù† Ø§ÛŒÙ†Ú©Ù‡ Ù…ØªÙ† base64 Ù‡Ø³Øª ÛŒØ§ Ù†Ù‡"""
        text = text.strip()
        if text.startswith(('vless://', 'vmess://')):
            return False
        pattern = re.compile(r'^[A-Za-z0-9+/]*={0,2}$')
        return len(text) > 20 and pattern.match(text)
    
    def decode_base64(self, content: bytes) -> str:
        """ØªØ¨Ø¯ÛŒÙ„ Ù…Ø­ØªÙˆØ§ Ø§Ø² base64 Ø§Ú¯Ù‡ Ù„Ø§Ø²Ù… Ø¨Ø§Ø´Ù‡"""
        try:
            text = content.decode('utf-8', errors='ignore').strip()
            
            # ØªØ§ Ûµ Ù„Ø§ÛŒÙ‡ base64 Ø±Ùˆ decode Ù…ÛŒâ€ŒÚ©Ù†Ù‡
            for _ in range(5):
                if self.is_base64(text):
                    try:
                        missing_padding = len(text) % 4
                        if missing_padding:
                            text += '=' * (4 - missing_padding)
                        decoded = base64.b64decode(text).decode('utf-8', errors='ignore').strip()
                        if decoded != text:
                            text = decoded
                        else:
                            break
                    except:
                        break
                else:
                    break
            
            return text
        except:
            return content.decode('utf-8', errors='ignore')
    
    def fetch_url(self, url: str) -> List[str]:
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø§Ø² ÛŒÚ© URL"""
        try:
            print(f"ğŸ“¥ Downloading: {url}")
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=15) as response:
                content = response.read()
                decoded = self.decode_base64(content)
                configs = [line.strip() for line in decoded.split('\n') if line.strip()]
                
                # ÙÙ‚Ø· Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ VLESS Ø±Ùˆ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ù‡
                vless_configs = [c for c in configs if c.startswith('vless://')]
                print(f"   âœ“ Found {len(vless_configs)} VLESS configs")
                return vless_configs
        except Exception as e:
            print(f"   âœ— Error: {e}")
            return []
    
    def fetch_all(self, urls: List[str]) -> List[str]:
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÙˆØ§Ø²ÛŒ Ø§Ø² Ù‡Ù…Ù‡ URL Ù‡Ø§"""
        print("\n" + "="*60)
        print("ğŸ“¥ Fetching configs from all URLs...")
        print("="*60)
        
        all_configs = []
        
        # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø§ Û±Û° thread
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = {executor.submit(self.fetch_url, url): url for url in urls}
            
            for future in as_completed(futures):
                configs = future.result()
                all_configs.extend(configs)
        
        print(f"\nâœ“ Total downloaded: {len(all_configs)} configs")
        return all_configs
    
    def remove_duplicates(self, configs: List[str]) -> List[str]:
        """Ø­Ø°Ù Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ"""
        print("\nğŸ”„ Removing duplicates...")
        unique = list(set(configs))
        print(f"âœ“ Unique configs: {len(unique)} (removed {len(configs) - len(unique)} duplicates)")
        return unique
    
    def extract_transport_type(self, config: str) -> str:
        """ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ transport Ø§Ø² Ú©Ø§Ù†ÙÛŒÚ¯"""
        try:
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† query string
            if '?' not in config:
                return 'tcp'
            
            query_string = config.split('?')[1].split('#')[0]
            params = {}
            
            for param in query_string.split('&'):
                if '=' in param:
                    key, value = param.split('=', 1)
                    params[key] = value
            
            # Ú†Ú© Ú©Ø±Ø¯Ù† type
            transport = params.get('type', 'tcp')
            
            # Ú†Ú© Ú©Ø±Ø¯Ù† security Ø¨Ø±Ø§ÛŒ TLS
            security = params.get('security', 'none')
            
            # Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ
            if transport == 'ws':
                return 'ws'
            elif transport == 'grpc':
                return 'grpc'
            elif transport == 'httpupgrade' or transport == 'xhttp':
                return 'xhttp'
            elif security == 'tls':
                return 'tls'
            else:
                return 'tcp'
                
        except:
            return 'tcp'
    
    def categorize_by_transport(self, configs: List[str]) -> Dict[str, List[str]]:
        """Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ transport"""
        print("\nğŸ“Š Categorizing by transport type...")
        
        categories = defaultdict(list)
        
        for config in configs:
            transport = self.extract_transport_type(config)
            categories[transport].append(config)
        
        # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±
        for transport, confs in categories.items():
            print(f"   {transport.upper()}: {len(confs)} configs")
        
        return dict(categories)
    
    def save_all_configs(self, configs: List[str], output_dir: str):
        """Ø°Ø®ÛŒØ±Ù‡ ØªÙ…Ø§Ù… Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„"""
        filepath = os.path.join(output_dir, 'all_vless_config.txt')
        with open(filepath, 'w', encoding='utf-8') as f:
            for config in configs:
                f.write(config + '\n')
        print(f"\nâœ“ Saved all configs to: all_vless_config.txt")
    
    def save_by_transport(self, categories: Dict[str, List[str]], output_dir: str):
        """Ø°Ø®ÛŒØ±Ù‡ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© transport"""
        print("\nğŸ’¾ Saving categorized configs...")
        
        for transport, configs in categories.items():
            filepath = os.path.join(output_dir, f'vless_{transport}.txt')
            with open(filepath, 'w', encoding='utf-8') as f:
                for config in configs:
                    f.write(config + '\n')
            print(f"   âœ“ vless_{transport}.txt ({len(configs)} configs)")
    
    def split_configs(self, configs: List[str], output_dir: str):
        """Split Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¨Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Û³Û°Û° ØªØ§ÛŒÛŒ"""
        print(f"\nâœ‚ï¸  Splitting into {self.split_size}-config files...")
        
        total_files = (len(configs) + self.split_size - 1) // self.split_size
        
        for i in range(0, len(configs), self.split_size):
            chunk = configs[i:i + self.split_size]
            file_num = (i // self.split_size) + 1
            filepath = os.path.join(output_dir, f'vless_config_{file_num}.txt')
            
            with open(filepath, 'w', encoding='utf-8') as f:
                for config in chunk:
                    f.write(config + '\n')
        
        print(f"   âœ“ Created {total_files} split files")
    
    def update_readme(self, output_dir: str, repo_url: str):
        """Ø¨Ù‡ Ø±ÙˆØ² Ú©Ø±Ø¯Ù† README Ø¨Ø§ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ raw"""
        print("\nğŸ“ Updating README.md...")
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ txt
        files = [f for f in os.listdir(output_dir) if f.endswith('.txt')]
        files.sort()
        
        # Ø³Ø§Ø®Øª Ù…Ø­ØªÙˆØ§ÛŒ README
        readme_content = f"""# ğŸš€ VLESS Configs Repository

Auto-updated every 6 hours with fresh VLESS configurations.

## ğŸ“Š Statistics

- **Total Files**: {len(files)}
- **Last Update**: Auto-generated
- **Update Frequency**: Every 6 hours

## ğŸ“ Available Files

### All Configs
"""
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ raw
        for file in files:
            # Ø³Ø§Ø®Øª URL raw
            raw_url = f"{repo_url}/raw/main/configs/{file}"
            readme_content += f"\n- [{file}]({raw_url})"
        
        readme_content += """

## ğŸ”— How to Use

Copy any raw link above and add it as a subscription in your V2Ray client.

### Example:
```
https://raw.githubusercontent.com/YOUR_USERNAME/YOUR_REPO/main/configs/vless_config_1.txt
```

## âš™ï¸ Transport Types

Configs are categorized by transport protocol:
- **WS**: WebSocket
- **gRPC**: Google RPC
- **TCP**: Standard TCP
- **TLS**: With TLS encryption
- **XHTTP**: HTTP Upgrade

---

*Auto-updated by GitHub Actions*
"""
        
        # Ø°Ø®ÛŒØ±Ù‡ README
        readme_path = os.path.join(os.path.dirname(output_dir), 'README.md')
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        print("   âœ“ README.md updated with raw links")

def main():
    import sys
    
    # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§
    if len(sys.argv) < 2:
        print("Usage: python3 simple_processor.py <subscriptions_file>")
        sys.exit(1)
    
    subs_file = sys.argv[1]
    
    # Ø®ÙˆØ§Ù†Ø¯Ù† Ù„ÛŒØ³Øª subscription Ù‡Ø§
    if not os.path.exists(subs_file):
        print(f"âœ— File not found: {subs_file}")
        sys.exit(1)
    
    with open(subs_file, 'r') as f:
        urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    
    print(f"ğŸ“‹ Found {len(urls)} subscription URLs")
    
    # Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡ output
    output_dir = 'configs'
    os.makedirs(output_dir, exist_ok=True)
    
    # Ù¾Ø±Ø¯Ø§Ø²Ø´
    processor = SimpleProcessor(split_size=300)
    
    # Ø¯Ø§Ù†Ù„ÙˆØ¯
    all_configs = processor.fetch_all(urls)
    
    if not all_configs:
        print("\nâœ— No configs downloaded!")
        sys.exit(1)
    
    # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒ
    unique_configs = processor.remove_duplicates(all_configs)
    
    # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
    categories = processor.categorize_by_transport(unique_configs)
    
    # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
    processor.save_all_configs(unique_configs, output_dir)
    processor.save_by_transport(categories, output_dir)
    processor.split_configs(unique_configs, output_dir)
    
    # Ø¨Ù‡ Ø±ÙˆØ² Ú©Ø±Ø¯Ù† README
    # Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ URL repository Ø®ÙˆØ¯ØªÙˆÙ† Ø±Ùˆ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø°Ø§Ø±ÛŒØ¯
    repo_url = "https://github.com/Matt-Ranaei/vless"  # Ø§ÛŒÙ† Ø±Ùˆ ØªØºÛŒÛŒØ± Ø¨Ø¯ÛŒØ¯
    processor.update_readme(output_dir, repo_url)
    
    print("\n" + "="*60)
    print("âœ… All done!")
    print("="*60)
    print(f"ğŸ“ Output directory: {output_dir}/")
    print(f"ğŸ“Š Total unique configs: {len(unique_configs)}")
    print(f"ğŸ“ README.md updated with raw links")
    print("="*60)

if __name__ == '__main__':
    main()
